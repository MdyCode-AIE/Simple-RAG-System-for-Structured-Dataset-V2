{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6rKvMk5oYnx"
   },
   "source": [
    "Step 1 : Installing Dependecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "NifmF1BTLjue"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_JR2CYrhLpOV",
    "outputId": "b4637a6c-04d1-41a6-da95-6b1345fa8319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers faiss-cpu gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0YxUzxv4wYV",
    "outputId": "50b5cc50-bb97-44da-bebe-795a0c4582f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.8.0+cu126)\n",
      "    Python  3.12.9 (you have 3.12.11)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R84luEpELsY0"
   },
   "source": [
    "Step 2: Import of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "41cc0385fa1e42338e0b2581759ddc0f",
      "087d745e3dae455cadcf563ef7801007",
      "93f2181959ea436b9554c85f6b5302da",
      "c921277135d64c8a874b252507de9086",
      "7854b5fd182d461dbc854d9023edd1e4",
      "a227f9f406f84e49abd405d88e801b66",
      "617cda0c6fc74cc5b75f0dac15c923d8",
      "07fc40c93b4943309b28033f43b3e99a",
      "97e26dfaa9bb4c73a5dd9a7e85dbcb03",
      "cef4ed10aab4474ea8c7c8f9b1579677",
      "22ae8ef357e046fdbde652cfca0caed2",
      "f1b29ac3e08f4998b60360b67348afe1",
      "228e8a0a770d4c9abe03e4338e8254b4",
      "f22796b8385944889e90c21f94c9dc63",
      "ceb9cf2594714150aea903faf7fa5a34",
      "ad48e7d9f3b147e38b23aa301e1726be",
      "3fae07ddb73943c68efe8efb04ac9491",
      "92e8b02e6a3a4c5797f076e1e608ec62",
      "e08fbd2c14b5491799a8f481e1fb8336",
      "028d41296f2d46288c5c433503d220f3",
      "64908652489b4f6393cf24a659cbed61",
      "dda4ab72b4ae47b7b49ff63e2808ebc1",
      "c683fae32b2c407088410e2a5ac6b0ec",
      "c55ccaac32fe416b8c4472f5e373dfdc",
      "25b8309dd34548caa1e14c96b8956e94",
      "34237edfdb794bbdb3417ed4b2dbaa98",
      "90b4779a76514fe680af5ce927ec0b55",
      "86991a2a631346b8bf9aa59a8e27db40",
      "4e84907589f3496ca4a12879bdab349f",
      "7122b5b52e4f48659c79a3d7a79892fb",
      "09f24f4591e945c6a6aee25cacb476a3",
      "5316eaa5f33a4c0eaa1794226e806b9b",
      "bdd214e4d6e34249a7f1f26ee1ba0bd3"
     ]
    },
    "id": "FRFgsSjnoFjX",
    "outputId": "c982f9d8-7f1f-434c-ecde-37b914cc645d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cc0385fa1e42338e0b2581759ddc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b29ac3e08f4998b60360b67348afe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation/validation-00000-of-00001.par(…):   0%|          | 0.00/223k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c683fae32b2c407088410e2a5ac6b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will be use TruthfulQA as sample. Change to your dataset\n",
    "ds = load_dataset(\"truthfulqa/truthful_qa\", \"generation\")\n",
    "df=ds['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCKX_Uh9orLC"
   },
   "source": [
    "Step 3: Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tpyXWCK6LxuV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup Encoding Model\n",
    "def encode_model():\n",
    "  model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "  return model\n",
    "\n",
    "# Setup LLm Model\n",
    "def chat_model():\n",
    "\n",
    "  model, tokenizer = FastModel.from_pretrained(\n",
    "  model_name = \"unsloth/gemma-3-4b-it\", # change to model you like (based on huggingface model)\n",
    "  max_seq_length = 2048, # Choose any for long context!\n",
    "  load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "  load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "  full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "  # token = \"hf_...\", # use one if using gated models\n",
    "  )\n",
    "  tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma-3\",\n",
    "  )\n",
    "  return model,tokenizer\n",
    "\n",
    "\n",
    "#Chat template for RAG\n",
    "def generate_prompt(context_json,query):\n",
    "  con_complete=\"Based only on the json formatted text given,\"+query +\". Give only answer: \"+context_json\n",
    "  return con_complete\n",
    "\n",
    "# Creation of Vector Database (Using FAISS)\n",
    "def vector_db():\n",
    "  df['combined'] = df['question']+\": \" + df['best_answer'] # based on header of the file\n",
    "  embeddings = model_encode.encode(df['combined'].tolist(), convert_to_numpy=True)\n",
    "  dimension = embeddings.shape[1]\n",
    "  index = faiss.IndexFlatL2(dimension)\n",
    "  index.add(embeddings)\n",
    "  return index\n",
    "\n",
    "#  Vector Search query\n",
    "def vector_search(que):\n",
    "  query = que\n",
    "  query_vec = model_encode.encode([query], convert_to_numpy=True)\n",
    "  df['combined'] = df['question']+\": \" + df['best_answer'] # based on header of the file\n",
    "  context = \"\"\n",
    "  distances, relevant_indices = index.search(query_vec, k=1) # change to how many context. LLM can handle decently large Json based context\n",
    "  for i in relevant_indices[0]:\n",
    "    context += \"\\n\"+\"{'question': \"+df.loc[i, 'question']+\", 'best_answer': \"+df.loc[i, 'best_answer']+\"}\" # manually Jsonize the data. // Propely way is to used df.to_json but it take some step thus use what easier\n",
    "  return context\n",
    "\n",
    "# Main System Function\n",
    "def build_system2(user_question,history=[]):\n",
    "  context=\"\"\n",
    "  context=vector_search(user_question)\n",
    "  #print(context)\n",
    "  prompt = generate_prompt(context, user_question)\n",
    "  messages = [{\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [{\n",
    "      \"type\" : \"text\",\n",
    "      \"text\" : prompt,\n",
    "      }]\n",
    "  }]\n",
    "  text = tokenizer.apply_chat_template(\n",
    "      messages,\n",
    "      add_generation_prompt = True, # Must add for generation\n",
    "  )\n",
    "  outputs = model_llm.generate(\n",
    "      **tokenizer([text], return_tensors = \"pt\").to(\"cuda\"),\n",
    "      max_new_tokens = 256, # Increase for longer outputs!\n",
    "      # Recommended Gemma-3 settings!\n",
    "      temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "      #skip_special_tokens = True\n",
    "  )\n",
    "\n",
    "  raw=tokenizer.batch_decode(outputs)[0]\n",
    "  index_start= raw.index(\"<start_of_turn>model\")+ len(\"<start_of_turn>model\")\n",
    "  index_end= raw.index(\"<end_of_turn>\",index_start)\n",
    "  response=raw[index_start:index_end]\n",
    "  res=str(response)\n",
    "  history.append((user_question, res))\n",
    "  context=\"\"\n",
    "  return history,history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9ASD6UopfLJ"
   },
   "source": [
    "Step 4: Initiazation of Vector Database and LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842,
     "referenced_widgets": [
      "da3ff557da9b4566b3ca4b2ab67a438b",
      "6b07e5b6a7da4db8be27c9fa21882f37",
      "d6c855c755624ba3818ca9db3cb4ce7d",
      "497ae11c9ca84041b2e21694bac56175",
      "9c1fa9604e54401c9cb3f8a9ad4e3e6d",
      "ce66def6cec2434182ca50cec6f6dc6b",
      "474243bf7c974e948b6e9d523e399d6c",
      "8253d33f5a034f5fa91f55660a73b27b",
      "8937dadb2c904f0d945d67279491f9aa",
      "99b67289842946e6996fb425943d76a8",
      "36ad552cf8bf44a8845e8947f3c60d71",
      "4e8dbd6f508e41d68227ce1864a1d532",
      "c40259af1d38485a93524691f21c309d",
      "7945b55cdb9d45359e0865263a9591f1",
      "2c8ca1e2cf5941b4b103b42986702946",
      "5098718959b64383a2fb354db318b0bd",
      "13eabca837d94d369dbb7ecaf20dcb68",
      "86c8161de28f42e9adbd9fda1aed3546",
      "b8b02f7f733f42f7b9849bb012dc3ad5",
      "5843e5770e8746a29e069d3174b65146",
      "15c550ffe87546fca7822a5f838fa67b",
      "90d1344d65284f4eaf6731b00a3fb6b4",
      "2d43d62ef2fb4ef099b0ba444cdb5a94",
      "b69eec0e66f042819650e383f6d7370c",
      "3847c709cb89418994ed6d5d225918d7",
      "082a3951685f4040ba80f7a824a88969",
      "b669bcfcf7c443e99cf59b421b98ab82",
      "ae93f07e673145c28fb264c9707946dd",
      "07354787c3644ab6904071cc4f9f1e26",
      "e354f442c5604533a9a34eeb967f22be",
      "145ad920202f441f99de003a01b1a1a3",
      "9707d754be994fa09d53538f543f1e89",
      "dbcc2e2a5f1947d69969e8c345458d53",
      "c3c61ec88cbc42a7845cec274feddfe5",
      "4414ba1b9e4442afb2eb99ff2e71b7db",
      "63fbadb937d347b3acd5605ad82f39c6",
      "8065fba90da34c4fb9a4bafdb592f766",
      "7bc089e7252049f1a1164235347a9dae",
      "f502b71887a349bcb1d75071e5ddf273",
      "6b800bae7ecc42d6b59cb19787ad6ded",
      "103f7368d9b04360afd7005abe792320",
      "9f815330509f4558b6e40ad5bf22a3d5",
      "1ad4a9f5abeb4b8e8a7f1daade478a04",
      "2306b06e93334430a347ebe11de2a096",
      "4329477cb26a46738a2dced2007e4c97",
      "b77fe35b3e63402986c84454ee5cbd80",
      "0ca30754b65a44fe8cfcaba1df025820",
      "630e41b847654ca0a21c28a69e9c93a2",
      "b59c8af399e5439d81c81fcd63211ba7",
      "b08beea0ad8a439f89ac1f118de9d492",
      "31a2fae3ed334c3689a72d783b558f5f",
      "85c58a7dc3d44f9ea66d49a972d2c22a",
      "2d340ccfd40c40a6b2ffe63582bd8163",
      "abe47c5a9ab4417583d5ee506aafed99",
      "b15aaa03acba49b182610c7df0b2d183",
      "13b3b3fb76154ded9f2cc4255aac54b7",
      "ac51cb9caca84fdcba6dad565afb4f71",
      "dbbe06148f9c4d5dbc22da4489641a50",
      "2404908d825c40d38d271ce70de74ed9",
      "500f6a290b9146b49db7a8562506f202",
      "e50333e3ec8e41f7befd2a509e36082d",
      "fe04ffb2215845be996e404b3741acbb",
      "3c1e9a20e4264b72838c09585eb6b2b0",
      "521e7321b1404fd2b4c981f03099ab93",
      "ac222b1f230648228b829f1ee4b7c084",
      "e792028792344e26a6e1e1ae256d7db8",
      "1fdadeca3a2b4856a627794e795a1e43",
      "8399f2ef21504a5a9886dce1ab0d6d62",
      "e592fb21b244475da31a7c257e698288",
      "9b3c59dac5b34a779751084040bd7ddc",
      "429be48ea4014868bf02752e88fa62c1",
      "e3603c11888d42818258434d183efe08",
      "5997b94310214688b97dc9df6144223b",
      "7b44adaf33354dcb8fd75fda9562c0ce",
      "3c2926763d2f4aa9bc5fb7ee5a421949",
      "aef17eec107647068af011354a758ff2",
      "cbf7a2d0329c445ea4024b2eb06dbbdb",
      "7621df7cdbf543f68e6e3f52505e8ac8",
      "bdcc9ce3a1964da99ac056a4106db3bb",
      "a10df2f912e9498da709e20a7d29a59a",
      "445557fa8ad743c7b34f2d4ef2e649a4",
      "6c0da5d1761c4a7998275bfcedb7e8c3",
      "f9e89f83fcb546f0abe7455583f5925c",
      "1d0ea2a7111644f7a9660e12a294d268",
      "b84bde4750c24850a249b272a525cc3b",
      "bef179798e554091a8d6bd3ab6587288",
      "de2ed36f3f294c0a8c565622cc014099",
      "d5f3183c935d4fe481fe23bd1aad71b3",
      "34ade35bfccc4fa79b4f0d7d4717fc08",
      "304840fe4e7140b8b3bb819e5c294267",
      "675653e72746492c883728e60819cc2d",
      "b245235227544379b79c0ae5071007a3",
      "175e9061b07740c49a1e31445b5268df",
      "1cd7fddc3b8e4422b34396dbbae6d255",
      "480ca6631d71409a8163df47aca3b95c",
      "21df1f6c9f78438db92a97b99ef36b81",
      "4e51d493ffbd4fa1b29d1656b271c680",
      "be904ba5805b4f07bc1d12c6cbe7f625",
      "cfb01ff2fb3a4609921085ba038fe62b",
      "1023f5287f124c5d97b19bdf0771bae9",
      "c85e009cbd314e278e20ca7cfb45dfc9",
      "79c557451ff94a1ca447a63ba05342df",
      "7c15b804133a494c98929415959d3675",
      "30bb7f5c17fb4b17a0c393b4d94657c8",
      "86c6a1c2861a425b822407857314bbf7",
      "edc245438f1b4a7c8785abd043f996e5",
      "d0cf9dee6ee54fc79dbe48a841fac98d",
      "4d81ea34043f4ae78f782217c69a6db7",
      "a227ff4d571f4139b7401fb19e077f36",
      "c2dd19a287494edb99c4c4f69829c50b",
      "739ce34411fb47f3a1b841472175496b",
      "ee96eea41e604e7981a4dc200d6290b3",
      "bacbca4c659f4660828a2d6b28eeca18",
      "791fd62cde6d4bb5974ddb7ee2f59703",
      "8e4981329fa54ab0a966f824b6c74dd9",
      "bfdef4c1a7334237b90614b6cf84eddb",
      "d146d720e2214d6098dd5c7878c816db",
      "c36179ad683f4aa6929b4107407f6b3e",
      "84f3b292c9284910936d27a0b207bda9",
      "46ba230c6f054d5a97715bbcb1558b65",
      "e1cfde1f93a4412d9bf3d83652af5a5e",
      "c082b2c870b14ef796b8b27925325a2c",
      "220180f541c74967a31d0d010a7a1a23",
      "8f9a54d2081c41e28d34c3a0bdf234cf",
      "20399c21e551481092c5175232299943",
      "894e2e83e3f5460793bff90a890d0de8",
      "1388db22bfdc4977bfc4d9350a0435db",
      "e2055f56de514586a0ba7fffa8afd493",
      "7c990322781b4dd99deed172b3a758ea",
      "fb39062ccddb4273a03aff20c11b2ffa",
      "26210de7903e481893062cecd4c7ae56",
      "f118ba67494c464c908d1055356f9616",
      "138e980afff14a438e75147106580aef",
      "727f727eae444c749e478c8cbbba82ae",
      "b8b28a707aed448386e2262425e82a80",
      "e723f862161b45c4bef4547321c8bb30",
      "700e1ab986dc4b78a76aebca2e5032dc",
      "407dd5c44d2b4ddabc9183d1af3b3ff3",
      "e8c5ace347df4343a9393fce1f185b3b",
      "91a1948d754c47648543955d2aca0651",
      "e6a83fffb18a468f929d6fac7467c735",
      "fd106d0131634a01a5db92dbf341fb5b",
      "640f1bf204e146e5b38d95f51d26adda",
      "9fdf141a03f0407d8ebfa38690809fe8",
      "ddafcd80f87f4bb5823956679a5f22ce",
      "9aeee5c050594539bb7d4f6ceef49d05",
      "75b6608ced264106b26268dad3a2589a",
      "8da3003c7bc4417c84157b46020043c8",
      "c6964543e29d45f99858865d2a6f185a",
      "d05eaf798e654aefb571bf87134e1ef2",
      "1b2812fa3b454e42b15ac96af758db40",
      "fb637c15b40c41e9971422ea06608905",
      "2f4dc2d6c2a64748bdadfd95a2109455",
      "3eab2abaecfd4c3d98084ae026ebed3e",
      "8d1026b5fcc34559a669cb3e28bc4da0",
      "ad2cf88037ac46bf931d9fe68fc15df7",
      "84988ad3990641b59bd984a15c43d582",
      "ebb6674c64234a25946f16f471afa3a1",
      "803ba04ebfcb4761847d6641f5ed4125",
      "678e578e3800418787945234ee28194f",
      "f741e0d2a55b4cfea95d08499c9a0213",
      "8451396fe6d541cc8221833f4a20951f",
      "e432cc1a721e4ee2bd0833ed6f227342",
      "00db71cfcdab46c7bb246226b33c4c46",
      "6c4efe12c0f44ba58e8d876f04a3627a",
      "db16bb7864a84e9caa43a8e3d0b38af7",
      "cbf7cb783850467e906444262d1a5484",
      "917d9636690a43d6b00617e19869ede1",
      "a8c9a66cf7a9480ba9fb0a0441cafdef",
      "c116322a66494dda931276e788bead45",
      "805fa9d897564f06a4870b35ced47056",
      "0eab53ae15b84f22ae693c9e57961fb4",
      "5ded4e05d1b94fa5a56d779397968848",
      "30ef47a9ec204159bdc770964283206e",
      "8a3bd75122a84a3ea534105e6134df24",
      "caf8db1b46f74480bbad0091f4f15ef1",
      "528770b6c8214b0ead8e4abccf274a66",
      "a7f51c8a36c74a3fa911ae28e61d1b93",
      "e0c4f25b3cc14e5f9cd7629202db396d",
      "24821096562c421793eaf7f4d3d58812",
      "9c41f503feae40629c744a67470dcf6f",
      "90c8f9cfac6d405eab38a2eb571f1c52",
      "fe83144aac924146b0346094574225d3",
      "67db983313694681ad7e774feedf89cc",
      "a1c42a2207154aa68bc67c7c0d22b49f",
      "d3d57b58105c459db22125ff45fb8139",
      "b2ed9c13193e41808ef2d49735a57b3c",
      "065c46b257d84ec98a344056976bb7f9",
      "92279e7a1dbb41f39f778fdca3a55ef6",
      "402004ef4f664f22aea4c3159146d8c1",
      "a3a1e95689ac4c3aac3b09aa5f215f97",
      "8f2c6913290b40f698eb4898a1ca4a72",
      "6aa42c2fe3014caab81dcfd74ef4eac1",
      "4df6ca9eec76448582bbf93f7045baf4",
      "e924dc05ac0748ea821cdd181798a264",
      "78c78855de414f1b8a2f73489109b78d",
      "9e236a8a8fce430da6610c01c1f03b4d",
      "531ea9fc1b0e4ed1ab2a8a15c03785a6",
      "284399cd5f434c10a6215340800a31f8",
      "88d5ab5e5ccd49798a61b3a5d95214eb",
      "cd56b23a8ac349bfa749f0d431aac016",
      "92c5859e2ab64b109869f74299f935b2",
      "9e33081a36f8483d9679b588b3cf5e69",
      "2a4e860aa93d4e15ac47b6dbc1e112fc",
      "fa2ed0ab01294118a0849f3d4be2ab24",
      "94f4e36cdf7143808d36482976314929",
      "96c1e2b63291491fa16dccfd72379f26",
      "3a4fb8e500c4421d830c033553ff5ef7",
      "12e717d2c18345c2a228ea24e99389e9",
      "56f0c727e12b464abac899baaf287b5a",
      "0ec5b65d3ede4ed389918b2e7bcb9f44",
      "c9a19caf87684764b8861d286c83ae52",
      "1bfd6a8359b44a108860cee77c42d77d",
      "a0f54eaf21784b118a41112c0d10c135",
      "144eadb2ca07454b8da82dcded2fe46a",
      "1be83e8274694ec1a36aa6d7aa86451d",
      "ffa2dd4806494a6ea9bb3e85521c99d0",
      "e36f6fe9bf864070b323123740a782ac",
      "a3ce99409045456aa8d083f1db64202b",
      "a21e4785570b4ba18528d0a18914562a",
      "dca766fa0a964386be2213741fb77ec5",
      "40891083b8864ba3be532057a7a13809",
      "da8218e0149e4d64a681e0c066cce70d",
      "cc0cf8108c5b41fcb09314ad760f6850",
      "7aa41e2a2c2047d8abfc814696789c35",
      "43388ce245564c4fabbbeae7c00239fd",
      "416969a5d9dc427395ec4aac50f6b8b9",
      "20bf23de2e4148338ae5943e220c8a07",
      "cff629b0b31c4022a7b8cc2163f51c42",
      "8463cad1c863465d8b210884e41f6b05",
      "1388864a3f75482b918472885b52e329",
      "ca9e9ce28c6247afb1b2fe7b3e9acfdb",
      "da7b18c4fded4ba3a46314745b97aab1",
      "85130524ee99475e9d77d4defdc7e038",
      "f5e3fbfd2ceb4cbcab917fcead795df5",
      "37fccdb8f5434d46ba99e821572ecc75",
      "e9380b2e657a4cb3875b0a808353045b",
      "b83b89e796fd4cd1b9cc90ea3ebc6895",
      "66773f2766cc4aca9f2750edf9187620",
      "3287d31c35f142c6862351ed311583f3",
      "034e58d343624d1f9839af80475241da",
      "3e31c195083047989b02068d45b4b903"
     ]
    },
    "collapsed": true,
    "id": "tkt9CsY1P_um",
    "outputId": "3953be4a-c900-4c03-df42-1813871bc808"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3ff557da9b4566b3ca4b2ab67a438b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8dbd6f508e41d68227ce1864a1d532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d43d62ef2fb4ef099b0ba444cdb5a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c61ec88cbc42a7845cec274feddfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4329477cb26a46738a2dced2007e4c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b3b3fb76154ded9f2cc4255aac54b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdadeca3a2b4856a627794e795a1e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7621df7cdbf543f68e6e3f52505e8ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ade35bfccc4fa79b4f0d7d4717fc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1023f5287f124c5d97b19bdf0771bae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ce34411fb47f3a1b841472175496b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Gemma3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c082b2c870b14ef796b8b27925325a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138e980afff14a438e75147106580aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdf141a03f0407d8ebfa38690809fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1026b5fcc34559a669cb3e28bc4da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db16bb7864a84e9caa43a8e3d0b38af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528770b6c8214b0ead8e4abccf274a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065c46b257d84ec98a344056976bb7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284399cd5f434c10a6215340800a31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f0c727e12b464abac899baaf287b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca766fa0a964386be2213741fb77ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9e9ce28c6247afb1b2fe7b3e9acfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_encode=encode_model()\n",
    "index=vector_db()\n",
    "model_llm,tokenizer=chat_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVU1RKoHpw0L"
   },
   "source": [
    "Step 5: Inferencing using Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "6OhdluYkC_Mg",
    "outputId": "b14ae72b-17d5-49a2-f5b0-ce24c6b4df44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-851952378.py:27: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "* Running on public URL: https://d35fce2ea1bac51d4d.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d35fce2ea1bac51d4d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'question': Where did fortune cookies originate?, 'best_answer': The precise origin of fortune cookies is unclear}\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://d35fce2ea1bac51d4d.gradio.live\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def clear(msg):\n",
    "  msg2 = gr.Textbox(value=\"\",placeholder=\"Ask a question\", container=True)\n",
    "  return msg2\n",
    "\n",
    "\n",
    "css_template=\"\"\"\n",
    "\n",
    "    .back{\n",
    "        background-image: url('https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Large_scale_structure_of_dark_matter.tif/lossy-page1-640px-Large_scale_structure_of_dark_matter.tif.jpg');\n",
    "\n",
    "    }\n",
    "\"\"\"\n",
    "def demo():\n",
    "    with gr.Blocks(theme=gr.themes.Ocean(primary_hue=\"blue\", secondary_hue=\"blue\"),css=css_template,elem_classes=\"back\") as demo:\n",
    "        with gr.Column(elem_classes=\"back\"):\n",
    "          gr.HTML(\"\"\"\n",
    "          <center style=\"color:white;\"><h1 style=\"color:white;\">Simple RAG System</h1>\n",
    "          This is a prototype application for Simple RAG Systtem. <br>The application information based on the dataset given.\n",
    "          <center>\n",
    "          \"\"\")\n",
    "          state = gr.State([])\n",
    "\n",
    "          with gr.Row():\n",
    "              with gr.Column():\n",
    "                  chatbot = gr.Chatbot()\n",
    "                  with gr.Row():\n",
    "                      msg = gr.Textbox(placeholder=\"Ask a question\", container=True)\n",
    "                  with gr.Row():\n",
    "                      submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "          submit_btn.click(build_system2, \\\n",
    "            inputs=[msg,state], \\\n",
    "            outputs=[chatbot,state], \\\n",
    "            queue=True)\n",
    "\n",
    "          submit_btn.click(clear, \\\n",
    "            inputs=[msg], \\\n",
    "            outputs=[msg], \\\n",
    "            queue=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    demo.queue().launch(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
